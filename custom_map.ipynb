{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-01-18T15:30:58.527897Z","iopub.status.busy":"2022-01-18T15:30:58.527125Z","iopub.status.idle":"2022-01-18T15:30:58.883905Z","shell.execute_reply":"2022-01-18T15:30:58.883156Z","shell.execute_reply.started":"2022-01-18T15:30:58.527775Z"},"trusted":true},"outputs":[],"source":["# Imports\n","import gym\n","import random\n","import numpy as np\n","import time\n","from gym.envs.registration import register\n","from IPython.display import clear_output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-18T15:30:58.886008Z","iopub.status.busy":"2022-01-18T15:30:58.885708Z","iopub.status.idle":"2022-01-18T15:30:58.909655Z","shell.execute_reply":"2022-01-18T15:30:58.908818Z","shell.execute_reply.started":"2022-01-18T15:30:58.885969Z"},"trusted":true},"outputs":[],"source":["env_name = \"FrozenLakeNoSlip-v1\" \n","custom_map = [\"SFFFFFFF\", \n","              \"FFFFFFFF\", \n","              \"FFFHFFFF\",\n","              \"FFFFFHFF\", \n","              \"FFFHFFFF\", \n","              \"FHHFFFHF\", \n","              \"FHFFHFHF\", \n","              \"FFFHFFFG\"]\n","N = len(custom_map)\n","register(\n","    id='FrozenLakeNoSlip-v0',\n","    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n","    kwargs={'is_slippery':False},\n","    max_episode_steps=400,\n","    reward_threshold=0.78,\n",")\n","\n","env = gym.make(env_name, desc = custom_map)\n","print(\"Observation space:\", env.observation_space)\n","print(\"Action space:\", env.action_space)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-18T15:30:58.912055Z","iopub.status.busy":"2022-01-18T15:30:58.911436Z","iopub.status.idle":"2022-01-18T15:30:58.921325Z","shell.execute_reply":"2022-01-18T15:30:58.92074Z","shell.execute_reply.started":"2022-01-18T15:30:58.912011Z"},"trusted":true},"outputs":[],"source":["class Agent():\n","    def __init__(self, env):\n","        self.is_discrete = \\\n","            type(env.action_space) == gym.spaces.discrete.Discrete\n","        \n","        if self.is_discrete:\n","            self.action_size = env.action_space.n\n","            print(\"Action size:\", self.action_size)\n","        else:\n","            self.action_low = env.action_space.low\n","            self.action_high = env.action_space.high\n","            self.action_shape = env.action_space.shape\n","            print(\"Action range:\", self.action_low, self.action_high)\n","        \n","    def get_action(self, state):\n","        if self.is_discrete:\n","            action = random.choice(range(self.action_size))\n","        else:\n","            action = np.random.uniform(self.action_low,\n","                                       self.action_high,\n","                                       self.action_shape)\n","        return action"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-18T15:31:07.313038Z","iopub.status.busy":"2022-01-18T15:31:07.312747Z","iopub.status.idle":"2022-01-18T15:31:07.324577Z","shell.execute_reply":"2022-01-18T15:31:07.323789Z","shell.execute_reply.started":"2022-01-18T15:31:07.313003Z"},"trusted":true},"outputs":[],"source":["class QAgent(Agent):\n","    \n","    def __init__(self, env, discount_rate=0.97, learning_rate=0.01):\n","        super().__init__(env)\n","        self.state_size = env.observation_space.n\n","        print(\"State size:\", self.state_size)\n","        \n","        self.epsilon = 1.0\n","        self.discount_rate = discount_rate\n","        self.learning_rate = learning_rate\n","        self.q_table = 1e-4 * np.random.random([self.state_size, self.action_size])\n","#         self.q_table = 1e-4 * np.zeros([self.state_size, self.action_size])\n","        \n","    def get_action(self, state):\n","        if random.random() < self.epsilon:\n","            return super().get_action(state)\n","        else:\n","            return np.argmax(self.q_table[state])\n","    \n","    def train(self, experience):\n","        state, action, next_state, reward, done = experience\n","        \n","        q_next = self.q_table[next_state]\n","        q_next = np.zeros([self.action_size]) if done else q_next\n","        q_target = reward + self.discount_rate * np.max(q_next)\n","        \n","        delta_q = q_target - self.q_table[state,action]\n","        self.q_table[state,action] += self.learning_rate * delta_q\n","        \n","        if done:\n","            self.epsilon *= 0.99"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-18T15:31:07.571839Z","iopub.status.busy":"2022-01-18T15:31:07.571299Z","iopub.status.idle":"2022-01-18T15:31:07.57584Z","shell.execute_reply":"2022-01-18T15:31:07.575288Z","shell.execute_reply.started":"2022-01-18T15:31:07.571803Z"},"trusted":true},"outputs":[],"source":["agent = QAgent(env)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-18T15:31:07.986002Z","iopub.status.busy":"2022-01-18T15:31:07.985514Z","iopub.status.idle":"2022-01-18T15:31:07.992291Z","shell.execute_reply":"2022-01-18T15:31:07.991718Z","shell.execute_reply.started":"2022-01-18T15:31:07.985966Z"},"trusted":true},"outputs":[],"source":["total_reward = 0\n","rounds = 5\n","num_eps = 100\n","\n","def run(rounds, num_eps, total_reward):\n","\n","    for _ in range(1, rounds + 1):\n","\n","        for _ in range(1, num_eps + 1):\n","            state = env.reset()\n","            done = False\n","            while not done:\n","                action = agent.get_action(state)\n","                next_state, reward, done, _ = env.step(action)\n","                agent.train((state,action,next_state,reward,done))\n","                state = next_state\n","                total_reward += reward\n","\n","#                 print(\"Round\", i)\n","#                 print(\"s:\", state, \"a:\", action)\n","#                 print(\"total reward:\", total_reward)\n","#                 env.render()\n","#                 print(agent.q_table)\n","#                 time.sleep(0.05)\n","#                 clear_output(wait=True)\n","\n","        total_reward = 0\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-18T15:31:13.641818Z","iopub.status.busy":"2022-01-18T15:31:13.641518Z","iopub.status.idle":"2022-01-18T15:31:15.667647Z","shell.execute_reply":"2022-01-18T15:31:15.666856Z","shell.execute_reply.started":"2022-01-18T15:31:13.641777Z"},"trusted":true},"outputs":[],"source":["run(rounds, num_eps, total_reward)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T08:15:26.394047Z","iopub.status.busy":"2022-01-17T08:15:26.393862Z","iopub.status.idle":"2022-01-17T08:15:26.408008Z","shell.execute_reply":"2022-01-17T08:15:26.406878Z","shell.execute_reply.started":"2022-01-17T08:15:26.394025Z"},"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"./{N}x{N}custom_frozen_lake_qtable.pkl\", \"wb\") as f:\n","    pickle.dump(agent.q_table, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:23:03.793722Z","iopub.status.idle":"2022-01-17T07:23:03.79414Z","shell.execute_reply":"2022-01-17T07:23:03.793975Z","shell.execute_reply.started":"2022-01-17T07:23:03.793954Z"},"trusted":true},"outputs":[],"source":["with open(f\"./{N}x{N}custom_frozen_lake_qtable.pkl\", \"rb\") as f:\n","    qtest = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:23:03.807147Z","iopub.status.idle":"2022-01-17T07:23:03.807431Z","shell.execute_reply":"2022-01-17T07:23:03.807297Z","shell.execute_reply.started":"2022-01-17T07:23:03.807282Z"},"trusted":true},"outputs":[],"source":["for episode in range(5):\n","    state = env.reset()\n","    step = 0\n","    done = False\n","    print(\"****************************************************\")\n","    print(\"EPISODE \", episode)\n","\n","    for step in range(400):\n","\n","        action = np.argmax(qtest[state, :])\n","        new_state, reward, done, info = env.step(action)\n","        state = new_state\n","        total_reward += reward\n","\n","        env.render()\n","\n","        time.sleep(0.05)\n","\n","        print(\"Number of steps\", step+1)\n","\n","        clear_output(wait=True)\n","        if done:\n","            break\n","\n","env.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T08:15:42.35439Z","iopub.status.busy":"2022-01-17T08:15:42.354111Z","iopub.status.idle":"2022-01-17T08:15:42.367315Z","shell.execute_reply":"2022-01-17T08:15:42.366144Z","shell.execute_reply.started":"2022-01-17T08:15:42.354361Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
