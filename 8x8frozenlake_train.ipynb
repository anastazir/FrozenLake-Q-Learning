{"cells":[{"cell_type":"code","execution_count":20,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-01-15T17:04:11.010370Z","iopub.status.busy":"2022-01-15T17:04:11.010048Z","iopub.status.idle":"2022-01-15T17:04:11.017396Z","shell.execute_reply":"2022-01-15T17:04:11.016322Z","shell.execute_reply.started":"2022-01-15T17:04:11.010338Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import gym\n","import random\n","import matplotlib.pyplot as plt\n","import pickle\n","import time\n","from IPython.display import clear_output\n","\n","%matplotlib inline\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T16:47:59.695460Z","iopub.status.busy":"2022-01-15T16:47:59.694429Z","iopub.status.idle":"2022-01-15T16:47:59.712059Z","shell.execute_reply":"2022-01-15T16:47:59.710970Z","shell.execute_reply.started":"2022-01-15T16:47:59.695409Z"},"trusted":true},"outputs":[],"source":["env = gym.make(\"FrozenLake8x8-v1\")\n","env.render()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T16:47:59.715163Z","iopub.status.busy":"2022-01-15T16:47:59.714521Z","iopub.status.idle":"2022-01-15T16:47:59.728169Z","shell.execute_reply":"2022-01-15T16:47:59.727048Z","shell.execute_reply.started":"2022-01-15T16:47:59.715114Z"},"trusted":true},"outputs":[],"source":["action_size = env.action_space.n\n","print(\"Action size: \", action_size)\n","\n","state_size = env.observation_space.n\n","print(\"State size: \", state_size)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T16:47:59.730532Z","iopub.status.busy":"2022-01-15T16:47:59.730120Z","iopub.status.idle":"2022-01-15T16:47:59.740828Z","shell.execute_reply":"2022-01-15T16:47:59.740070Z","shell.execute_reply.started":"2022-01-15T16:47:59.730480Z"},"trusted":true},"outputs":[],"source":["qtable_history = []\n","score_history = []\n","qtable = np.zeros((state_size, action_size))\n","\n","total_episodes = 250000       # Total episodes\n","learning_rate = 0.8           # Learning rate\n","max_steps = 400               # Max steps per episode\n","gamma = 0.9                  # Discounting rate\n","\n","epsilon = 1.0                 # Exploration rate\n","max_epsilon = 1.0             # Exploration probability at start\n","min_epsilon = 0.001            # Minimum exploration probability \n","decay_rate = 0.00005             # Exponential decay rate for exploration prob"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T16:47:59.744115Z","iopub.status.busy":"2022-01-15T16:47:59.743465Z","iopub.status.idle":"2022-01-15T16:58:18.991571Z","shell.execute_reply":"2022-01-15T16:58:18.990759Z","shell.execute_reply.started":"2022-01-15T16:47:59.744066Z"},"trusted":true},"outputs":[],"source":["rewards = []\n","\n","for episode in range(total_episodes):\n","    state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards = 0\n","    \n","    for step in range(max_steps):\n","        exp_exp_tradeoff = random.uniform(0, 1)\n","        \n","        if exp_exp_tradeoff > epsilon:\n","            action = np.argmax(qtable[state,:])\n","\n","        else:\n","            action = env.action_space.sample()\n","\n","        new_state, reward, done, info = env.step(action)\n","\n","        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n","        \n","        total_rewards += reward\n","        \n","        state = new_state\n","        \n","        if done == True: \n","            break\n","        \n","    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n","    rewards.append(total_rewards)\n","    \n","    episode_count = episode + 1\n","    if episode_count % 10000 == 0:\n","        qtable_history.append(qtable)\n","        score_history.append(sum(rewards)/episode_count)\n","\n","print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\n","print(qtable)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T17:00:26.274776Z","iopub.status.busy":"2022-01-15T17:00:26.274481Z","iopub.status.idle":"2022-01-15T17:00:26.307985Z","shell.execute_reply":"2022-01-15T17:00:26.306939Z","shell.execute_reply.started":"2022-01-15T17:00:26.274747Z"},"trusted":true},"outputs":[],"source":["env.reset()\n","total_test_episodes = 5\n","rewards = []\n","\n","for episode in range(total_test_episodes):\n","    state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards = 0\n","    #print(\"****************************************************\")\n","    #print(\"EPISODE \", episode)\n","\n","    for step in range(max_steps):\n","        # env.render()\n","\n","        # time.sleep(0.05)\n","        \n","        # clear_output(wait=True)\n","        action = np.argmax(qtable[state,:])\n","        \n","        new_state, reward, done, info = env.step(action)\n","        \n","        total_rewards += reward\n","        \n","        if done:\n","            env.render()\n","            rewards.append(total_rewards)\n","            print (\"Score\", total_rewards)\n","            print(\"Steps: \", step)\n","            break\n","        state = new_state\n","env.close()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T16:58:22.921791Z","iopub.status.busy":"2022-01-15T16:58:22.921573Z","iopub.status.idle":"2022-01-15T16:58:23.182350Z","shell.execute_reply":"2022-01-15T16:58:23.181203Z","shell.execute_reply.started":"2022-01-15T16:58:22.921763Z"},"trusted":true},"outputs":[],"source":["# Plotting score over time\n","plt.plot(list(range(0, 250000+1, 10000))[1:], score_history)\n","plt.title(\"Score vs. number of episodes\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T17:04:41.393444Z","iopub.status.busy":"2022-01-15T17:04:41.393055Z","iopub.status.idle":"2022-01-15T17:04:41.399126Z","shell.execute_reply":"2022-01-15T17:04:41.397954Z","shell.execute_reply.started":"2022-01-15T17:04:41.393395Z"},"trusted":true},"outputs":[],"source":["with open(\"8x8_frozen_lake_qtable.pkl\", \"wb\") as f:\n","    pickle.dump(qtable, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
